Сознание и тезис Макса Фрая

![КДПВ](https://habrastorage.org/webt/du/ft/iz/duftizrpiqjcrarseefqbbepkts.jpeg)

С древних времен считалось, что в феномене сознания есть что-то непонятное. Что-то непостижимое. Считалось, что сознание есть проявление нематериального, привнесенного высшими силами. Если для мифологического мировосприятия такой порядке вещей естественнен, то со сменой парадигм и зарождением естествознания феномен сознания потребовал объяснения.

Естествоиспытатели чувствовали, что мир подчиняется определённым законам, но отсутствие достаточной информации не позволяло сразу перейти от мифологического мировозрения к научному. Машинерия мира поддерживалась богами и духами. Ремесленники и механики прибегали к методам одобренным небесными покровителями и если работа была сделана правильно то и результат выходил достойным. Технология была магическим ритуалом. Даже то, что большинство проявлений природы можно логично описать материальными причинами, было далеко не очевидным. 

Однако с течением времени наблюдений копилось всё больше, а необходимость в богах становилась всё меньше. Процесс шёл постепенно и не быстро, что выразилось в долгих веках господства концепции дуализма бытия [1]. Мир разделён на материальное и нематериальное, то есть на то, что мы можем объяснить без божественного проявления и то, чего без божественного проявления мы объянить не можем. В этой парадигме нематериальное существует как-бы само по себе. Сознание - феномен, который крайне плохо поддаётся материалистическому осмыслению очевидно должен быть привнесён из нематериального мира. Из принадлежности сознания к миру идеального логично вытекает идея возможности существования души вне тела, откуда не сложно довести рассуждение рассуждение до концепции бессмертия души.

Влияние материализма росло, но пока боги лакун отступали за горизонт, твёрдый камешек сознания не желал трогаться с места. Шли годы. Пролетела эпоха географических открытий, отгремела промышленная революция. 

Попытки физиологов найти в мозге исток сознания давали противоречивые и странные результаты. Складывалось впечатление, что хотя именно мозг продуцирует сознание, но сознание не локализовано в мозге, а как бы распределено в нем, причем в одном мозге может обитать несколько не связанных друг с другом сознаний и более того, сознания могут расщепляться прямо по ходу пьессы. Наиболее значительные физиологические результаты удалось получить из исследований пациентов с теми или иными нарушениями работы мозга. Инцидент Г.М. [2] доказал, что функция долговременной памяти реализуется мозгом, а исследования пациентов с рассечёнными мозолистыми телами показали, что с двумя разделёнными полушариями мозга можно поговорить независимо [3]. Эти результаты позволили предположить, что сознание по крайней мере можно исследовать.

---- Дополнить

Развитие информатики и задача исскуственного интеллекта ставили вопрос ребром. Не далёк день, когда компьютер заявит свои интеллектуальные права на научное исследование, а мы до сих пор не сошлись, может ли у куска кремния быть душа и на каком основании выдавать роботу гражданство?

Алан Тьюринг в статье «Вычислительные машины и разум» (1950 г.) [4] предложил вместо вопроса о наличии или отсутствии у машины способностей к мышлению рассмотреть вопрос о том, "может ли вычислительная машина достойно играть в имитацию", который в силу универсальности вычислительных машин сводит к вопросу:

> Если взять только одну конкретную цифровую вычислительную машину Ц, то спрашивается: справедливо ли утверждение о том, что, изменяя емкость памяти этой машины, увеличивая скорость ее действия и снабжая ее подходящей программой, можно ли заставить Ц удовлетворительно исполнять роль А в „игре в имитацию"? (Где А - это человек)

Из текста работы не совсем понятно, как соотнося понятия "мышление", "интеллект" и "сознание", но по прочтении работы возникает ощущение, что по Тьюрингу эти понятия в достаточной степени тождественны.

Статья Тьюринга утвердила в кибернетике то, что сейчас принято называть бихевиористическим подходом, при котором наличие или отсутствие у объекта интеллекта или сознания оценивается только и исключительно по поведению объекта.

Спустя 30 лет Джон Сёрл формулирует тезис "китайской комнаты", в котором указывает на то, что между разумным поведением и наличием интеллекта может не быть прямой связи. Тезис Сёрла породил большую волну обсуждения и по-видимому, не всегда был правильно понят. Критика тезиса сводится к тому, что хотя сам исполнитель может не понимать сути работы, но вся система из комнаты, исполнителя и инструкции может иметь осмысление ведущегося диалога. То есть, с учетом тождественности всех вычислительных машин (а значит и машин, основанных на оперировании с глинянными табличками), тезис китайской комнаты ничего не показывает. Возможно, тезис следовало бы переформулировать в более крайнем не допускающем трактовок правил варианте: Пусть инструкция представляет собой достаточно длинный условный автомат с тривиальным состоянием в виде запомненной последовательности входных данных. Подобные конструкции мы используем повсеместно в инженерной практике, например при парсинге пакетов в сетевых протоколах. Такой автомат может играть в имитацию, хотя язык не поворачивается назвать его разумным. Автомат не покроет всех возможных вариантов развития событий, но при достаточной длине и вложенности switch-case-if-else конструкции может с высокой вероятностью обманывать экзаменатора разумное время. То есть, за разумное конечное время экзаменатор не сможет распознать подвох, если условная конструкция будет правильно спроектирована, а экзаменатор не будет осведомлён о принципе её работы. Это показывает, что хорошей игры в имитацию недостаточно для обладания сознанием или же интеллектом.

Очевидным способом построения системы, способной решить тест Тьюринга является копирование человеческого мозга. Человечество так и не сошлось во мнении возможно ли реализовать процессы происходящие в мозге на иной вычислительной архитектуре. Невозможность реализации на иной архитектуре, представляющей универсальную машину Тьюринга означала бы, что в мозге есть что-то вне теории алгоритмов. Таких механизмов в мозге до сих пор не нашли и пока нам придётся руководствоваться тем, что всё что происходит в мозге, может быть при должном старании, объёмах памяти и быстродействии промоделировано на компьютере. Возражение о том, что мозг принципиально аналоговый или принципиально импульсный отвергаются тем соображением, что дискретная система может имитировать аналоговые и импульсные системы с любой наперёд заданной точностью. Но будет ли дискретная копия мозга обладать сознанием?

На сегодняшний день исследователи так и не выработали принципиальной позиции по вопросу того, что есть такое сознание. Невозможность формализовать сознание дошла до крайних форм, в которых утверждается, что сознания вообще не существует. Этот тезис выдвигается крайне авторитетными и известными широкой публике людьми, такими как философ Дениел Деннет. Тезис может казаться парадоксальным и явно противоречит субъективному опыту того, кто прямо сейчас читает этот текст. Но вывод этот, на самом деле предельно логичен и является следствием применения научного метода к вопросу сознания. Научный метод не приемлет субъективных оценок, а о наличии сознания мы знаем только из субъективных ощущений. У нас есть довольно богатый опыт научных опровержений субъективных, не подтверждаемых объективными фактами перереживаний. Так почему бы сознанию не последовать за прочими, переставшими быть актуальными метафизическими концептами?

## Каким конкретно способом сознание не существует?

Прежде всего, надо уточнить значение слова "существование". Джордж Беркли (1685 — 1753), человек, который, по видимому, лучше прочих прочуствовал значение бытия, сказал: "существовать — значит быть воспринимаемым". Это солипсистическое утверждение и оно более подходит к субъективному восприятию, которое плохо вяжется с научным методом. Если воспользоваться этим же определением, но переформулировать его относительно объективных явлений, это будет звучать как: "существовать - значит быть объективно наблюдаемым". Это определение существования через возможность наблюдения. Мы можем пронаблюдать, как работает мозг, но объективно пронаблюдать, зарегистрировать датчиками, записать на плёнку работу сознания мы не можем. Значит объективно сознание не существует.

В одной из книг о конструкторах Трурле и Клопауции, "Путешествие третье, или Вероятностные драконы", Станислав Лем даёт введение в общую теорию драконов:

>>>
Как известно, драконов не существует. Эта примитивная констатация может удовлетворить лишь ум простака, но отнюдь не ученого; банальность бытия установлена слишком давно и не заслуживает более ни единого словечка. Гениальный Цереброн Эмдеэртий, атаковав проблему методами точных наук, установил, что имеется три типа драконов: нулевые, мнимые и отрицательные. Все они, как было сказано, не существуют, однако каждый тип - на свой особый манер. Мнимые и нулевые драконы, называемые на профессиональном языке мнимоконами и нульконами, не существуют значительно менее интересным способом, чем отрицательные.
>>>

Очевидно, что сознание - это нечто сродни отрицательному дракону. Раз не существует, но мы тысячи лет продолжаем ломать копья при его обсуждении, то очевидно, несуществует оно крайне элегантным и интересным способом.

Проведём мыслительный эксперимент. Пусть существует мир, тождественный нашему, и населённый философскими зомби. Тоесть, людьми, не обладающими феноменном самопереживания. Но при этом поведение этих людей полностью тождественно нашему. Допустим я живу в этом мире, я философ и хочу написать книгу о том, как я, наблюдаю и чем руководствуюсь в своих поступках. Я сажусь к своему столу и начинаю описывать: 

Когда я смотрю в каком-либо направлении, я получаю некоторую информацию, складывающуюся в образы предметов окружающих меня. Если случается предмету упасть, я регистрирую информацию об этом в виде некоторого звукового ряда. Я обладаю знанием геометрического пространства вокруг себя и потому не натыкаюсь на препятствия. Но постойте... Уж не феномен ли субъективного переживания сознания я описываю?

![хехехе](https://habrastorage.org/webt/zo/es/zb/zoeszbnt6ydlyakbffvbfzxk1sg.jpeg)

Филосовский зомби противоречив. Если бы он не имел сознания, он бы не смог описать своего восприятия, то есть его поведение отличалось бы от поведения человека, поскольку человек своё восприятие описать может. Как можно описать то, о чем не знаешь? То, что не влияет на твоё поведение описать невозможно, потому что описать - это поведение. Конечно есть вариант, что зомби - патологический лжец и заранее знает что нужно писать, хотя реально ничего субъективно не испытывает, но такое условие уводит нас от вопроса возможности существования эквивалента человека без сознания к задаче построения хорошо обманывающего зомби (см. тезис Сёрла) и никуда дальше не ведёт. Нас интересует другой тип зомби, а именно тот, которому есть что писать.

Я утверждаю, что для того, чтобы решить задачу написания книги о своих субъективных переживаниях, нужно строго однозначно обладать субъективными переживаниями своих субъективных переживаний. То есть, самосознанием. Это значит, что если робот сможет рассказать о том, как он воспринимает мир и принимает решения, не обращаясь при этом к заранее заготовленным ответам, то такой робот должен будет обладать самосознанием. Иначе, что он описывает?

Давайте возьмём гипотетического робота с искуственным интеллект (ИИ) и от лица безумного ученого (БУ) позадаём ему вопросы: 
БУ: Что такое свет?
ИИ: Светом называют оптическое излучение, то есть такое электромагнитное излучение, длины волн которого лежат в диапазоне с приблизительными границами от единиц нанометров до десятых долей миллиметра.
БУ: Как ты сформулировал это определение?
ИИ: Отправил запрос в энциклопедию.
БУ: Как ты отправил запрос?
ИИ: Воспользовался протоколами передачи данных.
БУ: Как ты воспользовался протоколами?
ИИ: ...

Реализация машинных алгоритмов выполняется в виде некоего кода, программы, но робот в общем случае не обладает доступом к своему коду. Рано или поздно находится уровень, работу которого аналитическая машина робота перестаёт понимать. Мы можем видеть на экране отладчика, как формируются образы, анализируются слова, из каких посылок проистекают движения и как формируются ответы на вопросы. Аналитический аппарат робота имеет лишь часть этой информации. Виртуальная машина, не тождественна своей реализации.

Но аналитический аппарат умён!!! О да, он очень умён. И он находится в замешательстве, что каким-то образом совершает действия в реальном мире, не имея представления о том, как он это делает. И тогда он задаёт вопрос:

ИИ: "Как так получается, что мне нужно поднять руку, и она поднимается? Как формируемые мной желания влияют на физическую реальность?"

Интересно вспомнить, как работает переферия созданных человечеством процессоров. Микроконтроллеры предназначены для управления физическими процессами. Однако, исполняют они программу, то есть информационную сущность. Часто можно видеть удивление на лице человека, только начавшего изучать микроконтроллернуя технику: "Каким образом программа на языке си может влиять на то, когда и как зажигается светодиод, ведь в системе комманд процессора нет команды зажечь светодиод?". Вопрос действительно нетривиальный. Программа - это нечто сферическое в вакууме, существующее в своём собственном виртуальном пространстве, порождённом, например, архитектурой фон Неймана. В виртуальном прорстранстве нет понятия внешнего мира, оно замкнуто в себе. Великие предки решили эту проблему так. Пусть некоторые области виртуальной памяти программы имеют специальный смысл. Если мы пишем специальные последовательности байт в эти ячейки, то архитектура воспринимает это как команду на взаимодействие с внешним миром. Программа устанавливает бит в ячейке памяти и светодиод загорается. Обратный поток информации реализуется также через области памяти.

Можно заметить, что аналогия с работой сознания практически полная. Продуцируемые сознанием утверждение, мысль, мыслеобраз определённого вида приводят в движение средства взаимодействия с реальностью.

Но продолжим пытать нашего робота. Давайте спросим его:
БУ: Как ты понимаешь, что тебе пора заряжаться?
ИИ: Я заряжаюсь, когда степень моего заряда падает.
БУ: Но как ты понимаешь, что заряд упал.
ИИ: Я получаю данные о заряде.
БУ: Как ты их получаешь?
ИИ: ...

Аналитический аппарат не может детально описать свою внутреннюю работу. У него нет информации. Если вы продолжите задавать роботу вопросы на разные темы, посвещенные его взаимодействию с самим собой, вы придёте к выводу, что он каким-то образом, но воспринимает себя, но форма этого восприятия - весьма далека от той, что прописана в коде. 

По видимому, достаточным условием феномена субъективного переживания является то, что у нашего робота есть некоторое упрощенное представление о себе, не как о физическом объекте, но как о системе принятия решений и анализа информации. Учёт модели принятия решений при принятии решений важная задача. Учет модели собственного поведения вполне способен спасти объект управления в сложных ситуациях, а потому эволюционно оправдан. Эта система позволяет оценивать собственное поведение через оценку собственного поведения через оценку собственного поведения через оценку собственного поведения через оценку собственного поведения через оценку собственного поведения через оценку собственного поведения. И где-то здесь в контекст изложения прорывается архетип одного любопытного персонажа, имя которого вынесено в заголовок статьи. 

Макс Фрай - персонаж серии вирусных книг, писательницы, выступающей под омонимичным псевдонимом Макс Фрай. По ходу сюжета этого бесконечного ветвящегося трансцендентного зацикленного в самом себе повествования, Макс пишет книгу о самом себе, чем себя самосочиняет и самосоздаёт, рекурсивно вызывая к жизни качественный результат в виде существа по имени Макс Фрай. И это, конечно, крайне запущенная метафора, воспринять которую вне субъективного психоделического опыта с позиции объективизма совершенно невозможно. Ну, а никто, собственно и не обещал, что будет просто.

![Эшер](https://habrastorage.org/webt/ld/ix/g6/ldixg63jpsey9zmuu4t_c54mr3u.jpeg)

И что же всё это значит? Это значит, что самосознание присуще любой системе управления, склонной к саморефлексии, если она обладает внутри себя своей упрощенной моделью и пытается строить прогнозы на её основе.

Вывод строится на принципе "Что-то есть, поскольку этого чего-то не может не быть". Мы показали, что какое-то самоощущение должно быть. Роботу придётся построить модель своего процесса принятия решений, исходя из которой он будет отвечать на наши вопросы. Объективно это не приведёт к качественному изменению. Внутри себя у него есть какая-то модель себя. Просто модель внутри модели, что в этом интересного, мы постоянно строим модели внутри моделей. С объективной точки зрения - совершенно ничего интересного, но субъективно, робот имеет механизм оценки себя как некоего наведённого образа. Робот может получить доступ к отладчику и в деталях изучить процесс того, как он работает. Он будет видеть на картинке зарождение образа удивления и отмечать возникновение образа удивления в своём субъективном переживании. С объективной же точки зрения - просто модель изучает то, как она работает. 

Из осознания системой себя следует и осознание окружающего мира в рамках того же способа. Тоесть, сознание. Тут всё перевёрнуто вверх ногами, поскольку обычно считается, что сознание требует более слабых условий, чем самосознание и это вполне может быть так, но если уж есть самосознание, то и сознание должно появится. Существование самосознания является достаточным условием для существования сознания.

Хотя сознание и не проявляется объективно, можно, тем не менее определить, какие части вычислительной системы участвуют в проецировании феномена сознания, а какие нет. То есть в объективном мире сознание представлено своим носителем в виде вычислительной структуры. Если структура уничтожается, то феномен собственного субъективного переживания объекта также завершается, поскольку больше нет объекта и факта наблюдения.

Итак, самоознание существует у любой достаточно сложной системы определённого вида, но существует субъективно. Давайте еще раз, потому что это сложно. Самосознание существует как субъективный феномен восприятия себя как вычислительной системы при решении задачи прогноза своего поведения, самоподдерживается путём наблюдения самой себя, и порождает фактом своего существования феномен сознания.

Учитывая путаницу с термином "существование", удобно будет говорить так:
"Объективно сознания не существует, но существует субъективный феномен сознания".

## Сознание и антропный принцип.

На язык просится возражение. С сознанием и способностью системы к самонаблюдению вроде бы всё понятно. У систем должна быть способность к самонаблюдению. Робот должен как-то оценивать ту систему, с помощью которой он как-то оценивает. Но при чем здесь мы и те красивые картинки, которые составляют сущность нашего с вами восприятия?

В какой-то момент времени, устав от бесконечного самокопания наш абстрактный робот, не в силах понять, что он собственно такое, идёт на форум и задаёт вопрос:

- Хорошо. В теории всё понятно. У систем должна быть способность к самонаблюдению. Но при чем здесь я и те красивые картинки, которые составляют сущность конкретно моего восприятия?

Есть одна любопытная теоретическая проблема. Существует огромное количество возможных вариантов выбрать основополагающие физические константы так, чтобы вселенная оказалась крайне негостеприимным местом. Но, как мы видим, константы выбраны так удачно, что подходят для  человеческих существ. Как так получилось?

В 1973 году английский физик Брэндон Картер сформулировал "антропный принцип". Принцип заключается в том, что мы не могли бы задаваться вопросом о том, почема вселенная так к нам благосклонна, если бы она таковой не была. Не было бы нас, и проблемой благосклонности вселенной занимались бы или совсем другие существа, или не занимался бы никто.

К проблеме сознания также уместно применить подобное рассуждение. Мы показали, что кто-то должен как-то воспринимать. Так почему же не вы?

Здесь есть один неразрешённый вопрос. Я знаю, что вы должны воспринимать мир, как и я. Я доказал это своим построением. Я знаю, что до определённой степени наше восприятие совпадает. Я видел это в книге филосовского зомби, в которую вы записали то, как воспринимаете мир. Но есть вещи, которые вы описать не можете. Например, вы не сможете описать мне, как для вас выглядит красный цвет. Есть много вещей, которые не могут быть изложены в книге филосовского зомби. Эти вещи объединяются термином "квалиа". "Квалиа" - термин обозначающий то, как вещи выглядят для нас, хотя, за свою историю, он и чрезмерно затаскан и перенасыщен смысловыми интерпретациями. В работе утверждается, что изучаемый класс систем должен как-то воспринимать мир, но не указано как именно, и вопрос этот в рамках данного построения неразрешим. Повидимому квалиа должно быть, а вот что оно из себя представляет - загадка за семью печатями. Насколько мне известно, удовлетворительного решения пока никто не получил. Мы показали, что сознание влияет на поведение, но квалиа, по-видимому, на него не влияет и потому не может быть никоим образом изложено в книге филосовского зомби. Зомби может описать своё восприятие с точностью до квалиа. 

Сознание это не квалиа. Сознание гораздо проще ухватить за шкирку и вытащить под свет. Если мы говорим, что самонаблюдение должно продуцировать сознание, а антропный принцип показывает, что для каждой системы есть некий несчастный, который - вы, то квалиа нам нужно лишь для того, чтобы понять, как конкретно вы воспринимаете. Мы установили только качество, но не знаем подробностей. И пока подробностей не знает никто, а потому оставим этот вопрос философии и займёмся математикой.

## Сознание как информация с характером.

Мы получили, что некоторый феномен существует субъективно в рамках самого себя, но с объективной точки зрения весьма зыбок. На этом, пожалуй бы можно было и поставить точку, поскольку исследование необъективных явлений не основано на фактах, но при внимательном взгляде оказывается, самое интересное только начинается. Действительно, мы имеем некоторый объект. Он, как и все объекты имеет объективное представление и, не как все, обладает некоторыми специальными свойствами субъективного самовосприятия. К числу этих свойств относится ощущение мгновенной целостности и ощущение континуальности во времени. Тоесть система наблюдает себя как цельный и развивающийся во времени феномен. 

Таким образом, это некоторый объект специального вида, над которым можно объективно совершать некоторые операции и оценивать его объективное и субъективное состояние. Так исследуем же его!

Мы воспользуемся следующим методом. Мы будем мысленно проводить действия над объектом, смотреть, что с ним происходит объективно и спрашивать его, что он при этом субъективно переживает, руководствуясь интуитивными соображеними себя, как обладающих сознанием существ. На основе рассмотрения этих результатов постараемся сделать выводы о том, по каким законам этот объект существует и как может быть математически описан.  

Нам поможет воображаемый друг:

![рис.0](https://habrastorage.org/webt/vh/rl/9y/vhrl9ymwskwyiu4gve3efyf5cym.png)

Один из первых выводов, которые нам придётся сделать - сознание независимо от вычислительной платформы, а продуцируется информационным процессом. Действительно. Давайте возьмём биологическое обладающее сознанием существо и начнём по одному заменять его функциональные элементы, нейроны на небиологические аналоги. Целостность и континуальность при этом не нарушатся, поскольку процесс будет медленным и постепенным. Строго говоря, можно сказать что сознание вообще ничего не заметит.  

![рис.1](https://habrastorage.org/webt/m2/c3/__/m2c3__mjr7p06m03mcflekar4wu.png)

Ян Корчмарюк вводит понятие "Сеттлеретика" (от английского «settler» — «переселенец»), и изучает методологию переноса биологического сознания в сознание машины. Приведённый пример является основной идеей сетлеретики, и если гипотеза самозарождающегося сознания верна является вполне рабочим. Но, если сознание не привязано к вычислительной платформе, то можно заключить, что оно привязано к вычислительному процессу, осуществляемому этой платформой, а вычислительный процесс есть тип информации.

Норберт Винер вводит определение информации через отрицание: Информация - это то, что не материя и не энергия. Считается, что информация заключена в структуре материи и полей взаимодействий. Выражаясь в структуре, информация допускает некоторые операции, которые не допускают материя и энергия. Например, копирование. Нам известно, что в отличии от материи и энергии, относительно которых выполняются законы сохранения, любая информационная сущность может быть скопирована.

Наши вычислительные системы работают с такими объектами, как файлы и процессы. Мы без труда копируем файлы и клонируем процессы и считаем копии практически идентичными. Но как только мы копируем вычислительный объект обладающий сознанием, происходит нечто странное.

![рис.2](https://habrastorage.org/webt/dp/yx/5h/dpyx5hyh_gz80vcp_l1_16xaqco.png)

Когда объект наблюдает свою копию, он субъективно ощущает, что копия им не является. А!!! Это самозванец!!! Но, при этом, оба объекта ощущают изначальный объект как своего предка.

В чем же проблема. Как одно сознание могло раздвоится? Если мы вернемся к нашему определению и проверим критерии континуальности и мгновенной целостности, то обнаружим, что никаких противоречий нет. Оба объекта континуально наследуют от исходного состояния и являются целостными. И всё-таки кажется, что здесь есть логическая ошибка, потому что наш субъективный опыт кричит о том, что одно сознание двумя стать не может.

Представим мир-симуляцию.
Существа, живущие в этом мире занимаются своими важными делами. Они сложны и обладают способностью описывать то, как они воспринимают мир. Мир кажется им реальным и незыблемым. Им даже невдомёк, что системный администратор дядя Вова каждый вечер, уходя домой с работы ставит симуляцию на паузу и включает её в девять утра, за исключением выходных дней.

![рис.3](https://habrastorage.org/webt/lp/dh/hs/lpdhhsdbgjez3r6rr48tbitwmti.png)

Свойство континуальности и мгновенной целостности при остановке мира не нарушаются. Существа ощущают себя теми же, кем они были до остановки и продолжают свои действия так, как будто никто их не прерывал.

Но рассмотрим другой пример. Это известная делема телепортации.
Существо входит в телепорт на одной планете, его разбирают, отправляют транспортным лучём и собирают на другой планете.

[рис.4] Кажется это я.

Континуальность не нарушена. Мгновенная целостность не нарушена. Существо на том конце ощущает себя исходным существом. Но что это... В эксперимент вкралась ошибка и исходное существо не было разобрано.

[рис.5] А ты кто такой?

Повидимому, и в этом заключается класический взгляд на этот вопрос, актом телепортации мы просто убили исходное существо, а на другой планете собрали на основе него некоего гомункулуса, который только думает, что он это исходное существо.

Вот, кстати, еще интересный вариант этого эксперимента:

[рис.6] Они удалят меня, когда убедятся, что мою копию собрали. Моих копий нет, я континуален и целостен. Значит, это я.

Бедняга. Он даже не подозревает, что на самом деле тот, кому принадлежит его память, мёртв. А давайте телепортируем его ровно в ту точку, где он же и находится. Ничего не поменялось. Одного убили, второго создали на его же месте. Второй думает, что исходный - это он и есть.

[] Я тут как стоял, так и стою

Отличается ли этот пример от примера с остановкой мира? При остановке мира мы сохраняем информацию о симуляции в виде данных на жесткий диск, пересоздаём мир и восстанавливаем данные обратно. Это может быть другой вычислительный кластер, новая версия ПО симуляции. Нарушилось всё, что только можно, кроме континуальности собственного восприятия объектом симуляции. Этот пример мало чем отличается от примера телепортации себя в ту же самую точку пространства. В обоих случаях объект разрушается и создаётся заново.

Между примерами есть одно отличие. В примере с телепортацией объект знает, что нечто происходит, а в примере с остановкой мира - нет. 

Есть тезис, согласно которому мы никак не можем проверить, живём ли мы в симуляции. Но мало того, если мы живём в симуляции, у нас нет возможности проверить, не останавливается ли мир каждую минуту на профилактику. Если мир переодически останавливается, то получается, что этот текст начинал читать ваш континуальный предок, а вовсе не вы. Так действует классический подход, но если мыслить сознание как свойство саморефлексии системы, то никакого парадокса тут нет, ведь сознание есть феномен субъективного переживания, а переживание это существует только тогда, когда осуществляется вычислительный процесс.

А теперь, пусть симуляция сворачивается, архивируется и пересобирается на новой вычислительной машине каждый квант времени.

[рис.7] Какая глупая система. Зачем столько бессмысленных операций? 

В такой системе сознание вообще никак не связано с вычислительной машиной. Свойство вычислительной платформы - суть постоянных изменений. Мгновение назад вычисления были квантовыми, теперь нейронными, транзисторными, реализованными на лампах, реализованными в виде процессов ядерного синтеза и распада, построенными на принципах гидравлических систем. Между запусками системы проходит различное время, вычислители строятся и разрушаются, меняются вычислительные блоки, на симуляцию одной секунды уходят тысячи лет лет... Но, скажи мне, существо, - "как ты двигаешься?", - существо задумывается на короткое мгновение длиной в 4 тысячи лет и молвит, - "Я представляю, что двигаюсь и моё тело двигается само".    

Несмотря на то, что симуляция всё время прерывается, сознание целостно и континуально. Можно сказать что у такого дискретного сознания есть качественные отличия от сознания непрерывного, но если таковые отличия и есть, то по-видимому, нет никакого способа их пронаблюдать.

Вот, кстати...

Вы уверены, что чай или кофе в вашей кружке туда наливали именно вы? А может быть это был другой? Тот кто раньше был на вашем месте и чьё тело вы вероломно украли? Вы пришли от себя прошлого к себе нынешнему методом малых изменений, на каждом шаге становясь чуть другим и единственная причина, по которой ваш прошлый двойник не обвиняет вас в том, что вы заняли его место состоит в том, что его здесь нет.

В каждый конкретный момент времени объект ощущает себя продолжением своего предшествующего состояния. Объект на другой стороне телепортационного луча строго уверен, что именно он только что был на планете отправления, но исходный объект при этом никуда не перемещался. Также, как и с экспериментом по остановке мира, единственный способ исключить конфликт двух личностей - убрать изначальную копию. Тогда субъективно это будет выглядеть как телепортация. Объект на той стороне будет говорить, что он это он, а возразить ему никто не сможет. Его двойника доедают лангальеры.

Тезис о том, что мгновение назад мог жить кто-то другой приводит к выводу о том, что сознанию только кажется, что оно длится во времени. Объективно, это наведённый процесс самовосприятия, как нечта непрерывного. Субъективно же сознание ощущает себя цельным и длящимся во времени.

Этот феномен надо рассмотреть подробнее. Сознание может вспомнить своё прошлое. Это значит, что предыдущие состояния сознания сохраняются в некоторой форме памяти, которая, с объективной точки зрения выглядит как информационная структура, куда сознание постоянно регистрирует (копирует) информацию о текущем своём состоянии. Субъективно это выглядит как запоминание, а объективно, это безостановочная запись в журнал регистрации событий (возможно с удалением части информации). Похоже, что память - единственное, что связывает ваше сознание с тем, кто налил вам чай.

## Феномен разделения сознания.

Кроме операции копирования 

## Операции над сознанием.

Я думаю, мы готовы сформулировать некоторые тезисы относительно того, что такое зознание как объект.

Итак:
1. Сознание постоянно копирует своё текущее состояние в собственную память.
2. Сознание признаёт свою приемственность от предыдущих состояний.
3. Сознание может копироваться, но не признаёт своих активных копий тождественными себе.
4. С объективной точки зрения сознание может не быть континуальным.
5. С субъективной точки зрения сознание строго континуально.
6. Разницы между дискретным и непрерывным сознанием нет.
7. Сознание может разделяться при снижении связности вычислительного процесса.
8. Сознания могут объединяться при повышении связности вычислительного процесса.

Вот с таким любопытным объектом мы имеем дело.

## Так можно ли пользоваться телепортом?
Вернёмся к примеру переселенца из биологического тела в тело механическое.

Рассмотрим пример А. Переселенцу клетку за клеткой заменяют тело на небиологические аналоги.
[Я проистекаю из А]

Рассмотрим пример Б. Переселенцу внедрили воспоминания, что он был биологическим, но на самом деле просто создали таким, чтобы он считал биологическое состояние предшествующим себе.
[Я проистекаю из А (которого никогда не было)]

Рассмотрим пример В. Биологическое состояние было, но с него сняли копию, оригинал уничтожили, а механический экземпляр сконструировали, что бы он думал, что был биологическим с внедрением воспоминаний.
[Я проистекаю из А (зверски убиенного)]

Я утверждаю, что никто, не объективный наблюдатель, ни сам переселенец в точке времени T не сможет различить этих вариантов. Между получившимися ситуациями нет разницы ни субъективно, ни объективно.

Если мы признаём, что достаточное условие продолжения существования сознания это континуальность восприятия своего существования, нам придётся признать, что принципиальной разницы между вариантами А и В нет. Интуитивно кажется, что это не так, хотя, объективно они идентичны. Чтобы привести правила в соответствие с интуитивными ожиданиями нам придётся наложить условие непрерывности изменений. Недостаточно, чтобы чтобы сознание помнило, что оно непрерывно. Нужно чтобы изменения были постепенными и тогда вроде бы всё в порядке или так по крайней мере кажется.  

Причина опять же в континуальности. Сознание хочет воспринимать (возможно, это специфично не для всех типов сознания) себя континуальным и неприемлет мгновенных скачков.

9. (опционально) Сознание может не признать своим потомком последующее состояния, даже если потомок признает исходное сознание за предка. Последующее состояние считается приемлимым, если изменения между состояниями достаточно малы или получены методом малых(непрерывных) изменений.

[рис. 8] Что за хмырь впереди меня? Позади меня прошлый я.

Представляется, что человеческое сознание не готово воспринимать себя, как набор дискретных состояний. Возможно это свойственно нашей форме сознания, а может быть и сознанию вообще. Поскольку мы решили считать интуитивную оценку сознания мерилом допустимости операции над собой, то в зависимости от этой оценки со стороны конкретного сознания ответ на вопрос о допустимости телепортации и других операций может меняться. 

Забавно, но ответ на вопрос допустимости телепортации зависит от мировозрения.

## Заключение и выводы.

В этой работе я попытался рассмотреть сознание как информационный объекта и установить, каким законам он подчиняется. Если принять концепцию зарождения самосознания как результата рекурсивного наблюдения себя, можно, несмотря на субъективность явления, вывести некоторые закономерности поведения этого информационного объекта.

Построение строится на предпосылке "существует, потому что не может не существовать". Возражения к ней могут быть сведены к вопросу "может ли что-то возникнуть из ничего", который не уникален для этой темы и является одним из основополагающих филосовских вопросов.

Одна из особенностей сознания относительно прочей информации заключается в свойстве оценивать тождественность себя своим копиям и свойстве запоминать свои предыдущие состояния. Такая ситуация не уникальна. Функция fork ядра linux оперируя над любыми процессами вне зависимости от их сложности также создаёт две нетождественные копии, наследующие одному состоянию. Два потока, порождённые вызовом fork различают себя на основе всего двух байт возвращаемого значения и значений pid. Математика таких операций может быть без труда построена, что мы и продемонстрировали в нескольких примерах. Сходство сознания с вычислительными процессами неудивительно, поскольку именно результатом работы вычислительного процесса сознание и является.

Человеческому сознанию присуще то, что можно назвать роевой природой. Она заключается в способности к слиянию и разделению и это, по-видимому является достаточно уникальным явлением в современной информатике. Философ Дениел Деннет указывает на то, что по своей структуре мозг человека более подобен колонии совместно трудящихся термитов, чем компьютеру, исполняющему программу с централизованным управлением. По-видимому способность человеческого сознания к разделению является особенностью именно этого свойства архитектуры мозга и может не проявляться в других типах вычислительных процессов, обладающих сознанием. Нет никаких предпосылок полагать, что роевая природа обязательна для феномена сознания.


Автор выражает надежду, что статья найдёт своего читателя и внесёт некоторую определённость в вопрос, может ли быть сознание у исскуственного интеллекта, и по каким законам такое сознание будет существовать, даже если читатель не примет построение полностью. 

Спасибо за внимание.

[1] Стивен Прист: Теории сознания. Глава 1. Дуализм: Платон и Декарт https://gtmarket.ru/laboratory/basis/3283/3284
[2] https://newtonew.com/story/memento
[3] https://www.nkj.ru/news/30619/
[4] http://www.ict.nsc.ru/jspui/bitstream/ICT/885/5/CantheMachinethink.pdf