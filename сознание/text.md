Сознание и тезис Макса Фрая

С древних времен считалось, что в феномене сознания есть что-то непонятное. Что-то непостижимое. Считалось, что сознание есть проявление нематериального, привнесенного высшими силами. Если для мифологического мировосприятия такой порядке вещей естественнен, то со сменой парадигм и зарождением естествознания феномен сознания потребовал объяснения.

Естествоиспытатели чувствовали, что мир подчиняется определённым законам, но отсутствие достаточной информации не позволяло сразу перейти от мифологического мировозрения к научному. Машинерия мира поддерживалась богами и духами. Ремесленники и механики прибегали к методам одобренным небесными покровителями и если работа была сделана правильно то и результат выходил достойным. Технология была магическим ритуалом. Даже то, что большинство проявлений природы можно логично описать материальными причинами, было далеко не очевидным. 

Однако с течением времени наблюдений копилось всё больше, а необходимость в богах становилась всё меньше. Процесс шёл постепенно и не быстро, что выразилось в долгих веках господства концепции дуализма бытия [1]. Мир разделён на материальное и нематериальное, то есть на то, что мы можем объяснить без божественного проявления и то, чего без божественного проявления мы объянить не можем. В этой парадигме нематериальное существует как-бы само по себе. Сознание - феномен, который крайне плохо поддаётся материалистическому осмыслению очевидно должен быть привнесён из нематериального мира. Из принадлежности сознания к миру идеального логично вытекает идея возможности существования души вне тела, откуда не сложно довести рассуждение рассуждение до концепции бессмертия души.

Влияние материализма росло, но пока боги лакун отступали за горизонт, твёрдый камешек сознания не желал трогаться с места. Шли годы. Пролетела эпоха географических открытий, отгремела промышленная революция. 

Попытки физиологов найти в мозге исток сознания давали противоречивые и странные результаты. Складывалось впечатление, что хотя именно мозг продуцирует сознание, но сознание не локализовано в мозге, а как бы распределено в нем, причем в одном мозге может обитать несколько не связанных друг с другом сознаний и более того, сознания могут расщепляться прямо по ходу пьессы. Наиболее значительные физиологические результаты удалось получить из исследований пациентов с теми или иными нарушениями работы мозга. Инцидент Г.М. [2] доказал, что функция долговременной памяти реализуется мозгом, а исследования пациентов с рассечёнными мозолистыми телами показали, что с двумя разделёнными полушариями мозга можно поговорить независимо [3]. Эти результаты позволили предположить, что сознание по крайней мере можно исследовать.

Развитие информатики и задача исскуственного интеллекта ставили вопрос ребром. Не далёк день, когда компьютер заявит свои интеллектуальные права на научное исследование, а мы до сих пор не сошлись, может ли у куска кремния быть душа и на каком основании выдавать роботу гражданство?

Алан Тьюринг в статье «Вычислительные машины и разум» (1950 г.) [4] предложил вместо вопроса о наличии или отсутствии у машины способностей к мышлению рассмотреть вопрос о том, "может ли вычислительная машина достойно играть в имитацию", который в силу универсальности вычислительных машин сводит к вопросу:

> Если взять только одну конкретную цифровую вычислительную машину Ц, то спрашивается: справедливо ли утверждение о том, что, изменяя емкость памяти этой машины, увеличивая скорость ее действия и снабжая ее подходящей программой, можно ли заставить Ц удовлетворительно исполнять роль А в „игре в имитацию"? (Где А - это человек)

Из текста работы не совсем понятно, как соотнося понятия "мышление", "интеллект" и "сознание", но по прочтении работы возникает ощущение, что по Тьюрингу эти понятия в достаточной степени тождественны.

Статья Тьюринга утвердила в кибернетике то, что сейчас принято называть бихевиористическим подходом, при котором наличие или отсутствие у объекта интеллекта или сознания оценивается только и исключительно по поведению объекта.

Спустя 30 лет Джон Сёрл формулирует тезис "китайской комнаты", в котором указывает на то, что между разумным поведением и наличием интеллекта может не быть прямой связи. Тезис Сёрла породил большую волну обсуждения и по-видимому, не всегда был правильно понят. Критика тезиса сводится к тому, что хотя сам исполнитель может не понимать сути работы, но вся система из комнаты, исполнителя и инструкции может иметь осмысление ведущегося диалога. То есть, с учетом тождественности всех вычислительных машин (а значит и машин, основанных на оперировании с глинянными табличками), тезис китайской комнаты ничего не показывает. Возможно, тезис следовало бы переформулировать в более крайнем не допускающем трактовок правил варианте: Пусть инструкция представляет собой достаточно длинный условный автомат с тривиальным состоянием в виде запомненной последовательности входных данных. Подобные конструкции мы используем повсеместно в инженерной практике, например при парсинге пакетов в сетевых протоколах. Такой автомат может играть в имитацию, хотя язык не поворачивается назвать его разумным. Автомат не покроет всех возможных вариантов развития событий, но при достаточной длине и вложенности switch-case-if-else конструкции может с высокой вероятностью обманывать экзаменатора разумное время. То есть, за разумное конечное время экзаменатор не сможет распознать подвох, если условная конструкция будет правильно спроектирована, а экзаменатор не будет осведомлён о принципе её работы. Это показывает, что хорошей игры в имитацию недостаточно для обладания сознанием или же интеллектом.

Очевидным способом построения системы, способной решить тест Тьюринга является копирование человеческого мозга. Человечество так и не сошлось во мнении возможно ли реализовать процессы происходящие в мозге на иной вычислительной архитектуре. Невозможность реализации на иной архитектуре, представляющей универсальную машину Тьюринга означала бы, что в мозге есть что-то вне теории алгоритмов. Таких механизмов в мозге до сих пор не нашли и пока нам придётся руководствоваться тем, что всё что происходит в мозге, может быть при должном старании, объёмах памяти и быстродействии промоделировано на компьютере. Возражение о том, что мозг принципиально аналоговый или принципиально импульсный отвергаются тем соображением, что дискретная система может имитировать аналоговые и импульсные системы с любой наперёд заданной точностью. Но будет ли дискретная копия мозга обладать сознанием?

На сегодняшний день исследователи так и не выработали принципиальной позиции по вопросу того, что есть такое сознание. Невозможность формализовать сознание дошла до крайних форм, в которых утверждается, что сознания вообще не существует. Этот тезис выдвигается крайне авторитетными и известными широкой публике людьми, такими как философ Дениел Деннет. Тезис может казаться парадоксальным и явно противоречит субъективному опыту того, кто прямо сейчас читает этот текст. Но вывод этот, на самом деле предельно логичен и является следствием применения научного метода к вопросу сознания. Научный метод не приемлет субъективных оценок, а о наличии сознания мы знаем только из субъективных ощущений. У нас есть довольно богатый опыт научных опровержений субъективных, не подтверждаемых объективными фактами перереживаний. Так почему бы сознанию не последовать за прочими, переставшими быть актуальными метафизическими концептами?

## А может ли сознания не быть?

Проведём мыслительный эксперимент. Пусть существует мир, тождественный нашему, и населённый философскими зомби. Тоесть, людьми, не обладающими феноменном самопереживания. Но при этом поведение этих людей должно быть полностью тождественно нашему. Допустим я живу в этом мире, я философ и хочу написать книгу о том, как я, воспринимаю и чем руководствуюсь в своих поступках. Я сажусь к своему столу и начинаю описывать: 

Когда я смотрю в каком-либо направлении, я получаю некоторую информацию, складывающиюся в образы предметов окружающих меня. Если случается предмету упасть, я регистрирую информацию об этом в виде некоторого звукового ряда. Я обладаю знанием геометрического пространства вокруг себя и потому не натыкаюсь на препятствия. Но постойте... Уж не феномен ли субъективного переживания сознания я описываю?

Филосовский зомби противоречив. Если бы он не имел сознания, он бы не смог описать своего восприятия, то есть его поведение отличалось бы от поведения человека, поскольку человек своё восприятие описать может. Как можно описать то, чего нет и о чем не знаешь? Даже то, что существует, но не влияет на твоё поведение описать невозможно. Конечно есть вариант, что зомби - патологический лжец и заранее знает что нужно писать, хотя реально ничего субъективно не испытывает, но такое условие уводит нас от вопроса возможности существования эквивалента человека без сознания к задаче построения хорошо обманывающего зомби (см. тезис Сёрла) и никуда дальше не ведёт. Нас интересует другой тип зомби, а именно тот, которому есть что писать.

Я утверждаю, что для того, чтобы решить задачу написания книги о своих субъективных переживаниях, нужно строго однозначно обладать субъективными переживаниями своих субъективных переживаний. То есть, самосознанием. Это значит, что если робот сможет рассказать о том, как он воспринимает мир и принимает решения, не обращаясь при этом к заранее заготовленным ответам, то такой робот должен будет обладать самосознанием. Иначе, что он описывает?

Реализация машинных алгоритмов выполняется в виде некоего кода, программы, но робот в общем случае не обладает доступом к своему коду. Мы можем видеть на экране отладчика, как формируются образы, анализируются слова, из каких посылок проистекают движения и как формируются ответы на вопросы. Сам робот не имеет этой информации. Если у робота есть достаточно развитый аналитический аппарат и он способен на вопросы отвечать, вы можете спросить его, - "Почему небо синее?". Это тривиально. Он ответит. Вы спросите, - "Тебе нравится картина Ильи Репина "Приплыли"?". Это вопрос сложнее, поскольку предполагает субъективную оценку, но ответ на него также не гарантирует наличия сознания. Но вы спросите, - "Как ты приводишь себя в движение?", и ему придётся сказать что-то вроде "Ну... У меня есть задача изменить местоположение и тело само двигается". Подробности вычислительного процесса скрыты от робота, он не знает механизма. Вы спросите, - "Что заставляет тебя заряжаться каждые шесть часов", - и он ответит, - "Что-то подсказывает мне, что мой заряд падает и я понимаю, что время пришло." Продолжая пытать его вопросами, вы придёте к выводу, что он каким-то образом, но воспринимает окружающий мир и форма этого восприятия далека от той, что прописана в коде. Он пребывает в субъективном переживании.

По видимому, достаточным условием феномена является то, что у нашего робота есть некоторое упрощенное представление о себе, не как о физическом объекте, но как о системе принятия решений и анализа информации. Учёт модели принятия решений при принятии решений важная задача. Учет модели собственного поведения вполне способен спасти объект управления в сложных ситуациях, а потому эволюционно оправдан. Эта система позволяет оценивать собственное поведение через оценку собственного поведения через оценку собственного поведения через оценку собственного поведения через оценку собственного поведения через оценку собственного поведения через оценку собственного поведения. И где-то здесь в контекст изложения прорывается архетип персонажа, имя которого я вынес в заголовок. 

Макс Фрай - персонаж серии вирусных книг, писательницы, выступающей под омонимичным псевдонимом Макс Фрай. По ходу сюжета этого бесконечного ветвящегося трансцендентного зацикленного в самом себе повествования, Макс пишет книгу о самом себе, чем себя самосочиняет и самосоздаёт, рекурсивно вызывая к жизни качественный результат в виде существа по имени Макс Фрай. И это, конечно, крайне запущенная метафора, воспринять которую вне субъективного психоделического опыта с позиции объективизма совершенно невозможно. Ну, а никто, собственно и не обещал, что будет просто.



И что же всё это значит? Это значит, что самосознание присуще любой системе управления, склонной к саморефлексии, если она обладает внутри себя своей упрощенной моделью и пытается строить прогнозы на её основе.

Вывод строится на принципе "Что-то есть, поскольку этого чего-то не может не быть". Мы показали, что какое-то самоощущение должно быть. Роботу придётся построить модель своего процесса принятия решений, исходя из которой он будет отвечать на наши вопросы. Объективно это не приведёт к качественному изменению. Внутри себя у него есть какая-то модель себя. Просто модель внутри модели, что в этом интересного, мы постоянно строим модели внутри моделей. С объективной точки зрения - совершенно ничего интересного, но субъективно, робот имеет механизм оценки себя как некоего наведённого образа. Робот может получить доступ к отладчику и в деталях изучить процесс того, как он работает. Он будет видеть на картинке зарождение образа удивления и отмечать возникновение образа удивления в своём субъективном переживании. С объективной же точки зрения - просто модель изучает то, как она работает. 

Из осознания системой себя следует и осознание окружающего мира в рамках того же способа. Тоесть, сознание. Тут всё перевёрнуто вверх ногами, поскольку обычно считается, что сознание требует более слабых условий, чем самосознание и это вполне может быть так, но если уж есть самосознание, то и сознание должно появится. Существование самосознания является достаточным условием для существования сознания.

Итак, самоознание существует у любой достаточно сложной системы определённого вида, но существует субъективно. Давайте еще раз, потому что это сложно. Самосознание существует как субъективный феномен восприятия себя как вычислительной системы при решении задачи прогноза своего поведения, самоподдерживается путём наблюдения самой себя, и порождает фактом своего существования феномен сознания.

В этом месте надо сделать выбор, который, впрочем, никак не повлияет на дальнейший анализ. Либо мы считаем, что субъективные переживания не объективны и тогда их как бы нет, но субъективно они как бы есть, либо мы говорим, что раз уж субъективные переживания присущи такому-то классу систем, то они существуют объективно. По сути и то и другое - просто форма описания одного и того же феномена и ни на что не влияет. Однако, я могу внести немного конкретики в этот вопрос. 

Хотя сознание и не проявляется объективно, можно, тем не менее определить, какие части вычислительной системы участвуют в проецировании феномена сознания, а какие нет. То есть в объективном мире сознание представлено своим носителем в виде вычислительной структуры. Если структура уничтожается, то феномен собственного субъективного переживания объекта также завершается, поскольку больше нет объекта и факта наблюдения.

## Сознание как вычислительный процесс. Что не так с сознанием?

Мы получили, что некоторый феномен существует субъективно в рамках самого себя, но с объективной точки зрения весьма зыбок. На этом, пожалуй бы можно было и поставить точку, поскольку исследование необъективных явлений не основано на фактах, но при внимательном взгляде оказывается, самое интересное только начинается. Действительно, мы имеем некоторый объект. Он, как и все объекты имеет объективное представление и, не как все, обладает некоторыми специальными свойствами субъективного самовосприятия. К числу этих свойств относится ощущение мгновенной целостности и ощущение континуальности во времени. Тоесть система наблюдает себя как цельный и развивающийся во времени феномен. 

Таким образом, это некоторый объект специального вида, над которым можно объективно совершать некоторые операции и оценивать его объективное и субъективное состояние. Так исследуем же его!

Мы воспользуемся следующим методом. Мы будем мысленно проводить действия над объектом, смотреть, что с ним происходит объективно и спрашивать его, что он при этом субъективно переживает, руководствуясь интуитивными соображеними себя, как обладающих сознанием существ. На основе рассмотрения этих результатов постараемся сделать выводы о том, по каким законам этот объект существует и как может быть математически описан.  

Нам поможет воображаемый друг:

[рис.0] вы будете экспериментировать на мне

Один из первых выводов, которые нам придётся сделать - сознание независимо от вычислительной платформы, а продуцируется информационным процессом. Действительно. Давайте возьмём биологическое обладающее сознанием существо и начнём по одному заменять его функциональные элементы, нейроны на небиологические аналоги. Целостность и континуальность при этом не нарушатся, поскольку процесс будет медленным и постепенным. Строго говоря, можно сказать что сознание вообще ничего не заметит.  

[рис.1] я - комок билогической слизи. ой, когда это я успел стать механическим.

Ян Корчмарюк вводит понятие "Сеттлеретика" (от английского «settler» — «переселенец»), и изучает методологию переноса биологического сознания в сознание машины. Приведённый пример является основной идеей сетлеретики, и если гипотеза самозарождающегося сознания верна является вполне рабочим. Но, если сознание не привязано к вычислительной платформе, то можно заключить, что оно привязано к вычислительному процессу, осуществляемому этой платформой, а вычислительный процесс есть тип информации.

Норберт Винер вводит определение информации через отрицание: Информация - это то, что не материя и не энергия. Считается, что информация заключена в структуре материи и полей взаимодействий. Выражаясь в структуре, информация допускает некоторые операции, которые не допускают материя и энергия. Например, копирование. Нам известно, что в отличии от материи и энергии, относительно которых выполняются законы сохранения, любая информационная сущность может быть скопирована.

Наши вычислительные системы работают с такими объектами, как файлы и процессы. Мы без труда копируем файлы и клонируем процессы и считаем копии практически идентичными. Но как только мы копируем вычислительный объект обладающий сознанием, происходит нечто странное.

[рис.2] Это не я! 

Когда объект наблюдает свою копию, он субъективно ощущает, что копия им не является. А!!! Это самозванец!!! Но, при этом, оба объекта ощущают изначальный объект как своего предка.

В чем же проблема. Как одно сознание могло раздвоится? Если мы вернемся к нашему определению и проверим критерии континуальности и мгновенной целостности, то обнаружим, что никаких противоречий нет. Оба объекта континуально наследуют от исходного состояния и являются целостными. И всё-таки кажется, что здесь есть логическая ошибка, потому что наш субъективный опыт кричит о том, что одно сознание двумя стать не может.

Представим мир-симуляцию.
Существа, живущие в этом мире занимаются своими важными делами. Они сложны и обладают способностью описывать то, как они воспринимают мир. Мир кажется им реальным и незыблемым. Им даже невдомёк, что системный администратор дядя Вова каждый вечер, уходя домой с работы ставит симуляцию на паузу и включает её в девять утра, за исключением выходных дней.

[рис.3] Тут ничегоше ---- ньки не случается

Свойство континуальности и мгновенной целостности при остановке мира не нарушаются. Существа ощущают себя теми же, кем они были до остановки и продолжают свои действия так, как будто никто их не прерывал.

Но рассмотрим другой пример. Это известная делема телепортации.
Существо входит в телепорт на одной планете, его разбирают, отправляют транспортным лучём и собирают на другой планете.

[рис.4] Кажется это я.

Континуальность не нарушена. Мгновенная целостность не нарушена. Существо на том конце ощущает себя исходным существом. Но что это... В эксперимент вкралась ошибка и исходное существо не было разобрано.

[рис.5] А ты кто такой?

Повидимому, и в этом заключается класический взгляд на этот вопрос, актом телепортации мы просто убили исходное существо, а на другой планете собрали на основе него некоего гомункулуса, который только думает, что он это исходное существо.

Вот, кстати, еще интересный вариант этого эксперимента:

[рис.6] Они удалят меня, когда убедятся, что мою копию собрали. Моих копий нет, я континуален и целостен. Значит, это я.

Бедняга. Он даже не подозревает, что на самом деле тот, кому принадлежит его память, мёртв. А давайте телепортируем его ровно в ту точку, где он же и находится. Ничего не поменялось. Одного убили, второго создали на его же месте. Второй думает, что исходный - это он и есть.

[] Я тут как стоял, так и стою

Отличается ли этот пример от примера с остановкой мира? При остановке мира мы сохраняем информацию о симуляции в виде данных на жесткий диск, пересоздаём мир и восстанавливаем данные обратно. Это может быть другой вычислительный кластер, новая версия ПО симуляции. Нарушилось всё, что только можно, кроме континуальности собственного восприятия объектом симуляции. Этот пример мало чем отличается от примера телепортации себя в ту же самую точку пространства. В обоих случаях объект разрушается и создаётся заново.

Между примерами есть одно отличие. В примере с телепортацией объект знает, что нечто происходит, а в примере с остановкой мира - нет. 

Есть тезис, согласно которому мы никак не можем проверить, живём ли мы в симуляции. Но мало того, если мы живём в симуляции, у нас нет возможности проверить, не останавливается ли мир каждую минуту на профилактику. Если мир переодически останавливается, то получается, что этот текст начинал читать ваш континуальный предок, а вовсе не вы. Так действует классический подход, но если мыслить сознание как свойство саморефлексии системы, то никакого парадокса тут нет, ведь сознание есть феномен субъективного переживания, а переживание это существует только тогда, когда осуществляется вычислительный процесс.

А теперь, пусть симуляция сворачивается, архивируется и пересобирается на новой вычислительной машине каждый квант времени.

[рис.7] Какая глупая система. Зачем столько бессмысленных операций? 

В такой системе сознание вообще никак не связано с вычислительной машиной. Свойство вычислительной платформы - суть постоянных изменений. Мгновение назад вычисления были квантовыми, теперь нейронными, транзисторными, реализованными на лампах, реализованными в виде процессов ядерного синтеза и распада, построенными на принципах гидравлических систем. Между запусками системы проходит различное время, вычислители строятся и разрушаются, меняются вычислительные блоки, на симуляцию одной секунды уходят тысячи лет лет... Но, скажи мне, существо, - "как ты двигаешься?", - существо задумывается на короткое мгновение длиной в 4 тысячи лет и молвит, - "Я представляю, что двигаюсь и моё тело двигается само".    

Несмотря на то, что симуляция всё время прерывается, сознание целостно и континуально. Можно сказать что у такого дискретного сознания есть качественные отличия от сознания непрерывного, но если таковые отличия и есть, то по-видимому, нет никакого способа их пронаблюдать.

Вот, кстати...

Вы уверены, что чай или кофе в вашей кружке туда наливали именно вы? А может быть это был другой? Тот кто раньше был на вашем месте и чьё тело вы вероломно украли? Вы пришли от себя прошлого к себе нынешнему методом малых изменений, на каждом шаге становясь чуть другим и единственная причина, по которой ваш прошлый двойник не обвиняет вас в том, что вы заняли его место состоит в том, что его здесь нет.

В каждый конкретный момент времени объект ощущает себя продолжением своего предшествующего состояния. Объект на другой стороне телепортационного луча строго уверен, что именно он только что был на планете отправления, но исходный объект при этом никуда не перемещался. Также, как и с экспериментом по остановке мира, единственный способ исключить конфликт двух личностей - убрать изначальную копию. Тогда субъективно это будет выглядеть как телепортация. Объект на той стороне будет говорить, что он это он, а возразить ему никто не сможет. Его двойника доедают лангальеры.

Тезис о том, что мгновение назад мог жить кто-то другой приводит к выводу о том, что сознанию только кажется, что оно длится во времени. Объективно, это наведённый процесс самовосприятия, как нечта непрерывного. Субъективно же сознание ощущает себя цельным и длящимся во времени.

Этот феномен надо рассмотреть подробнее. Сознание может вспомнить своё прошлое. Это значит, что предыдущие состояния сознания сохраняются в некоторой форме памяти, которая, с объективной точки зрения выглядит как информационная структура, куда сознание постоянно регистрирует (копирует) информацию о текущем своём состоянии. Субъективно это выглядит как запоминание, а объективно, это безостановочная запись в журнал регистрации событий (возможно с удалением части информации). Похоже, что память - единственное, что связывает ваше сознание с тем, кто налил вам чай.

## Феномен разделения сознания.

Кроме операции копирования 

## Операции над сознанием.

Я думаю, мы готовы сформулировать некоторые тезисы относительно того, что такое зознание как объект.

Итак:
1. Сознание постоянно копирует своё текущее состояние в собственную память.
2. Сознание признаёт свою приемственность от предыдущих состояний.
3. Сознание может копироваться, но не признаёт своих активных копий тождественными себе.
4. С объективной точки зрения сознание может не быть континуальным.
5. С субъективной точки зрения сознание строго континуально.
6. Разницы между дискретным и непрерывным сознанием нет.
7. Сознание может разделяться при снижении связности вычислительного процесса.
8. Сознания могут объединяться при повышении связности вычислительного процесса.

Вот с таким любопытным объектом мы имеем дело.

## Так можно ли пользоваться телепортом?
Вернёмся к примеру переселенца из биологического тела в тело механическое.

Рассмотрим пример А. Переселенцу клетку за клеткой заменяют тело на небиологические аналоги.
[Я проистекаю из А]

Рассмотрим пример Б. Переселенцу внедрили воспоминания, что он был биологическим, но на самом деле просто создали таким, чтобы он считал биологическое состояние предшествующим себе.
[Я проистекаю из А (которого никогда не было)]

Рассмотрим пример В. Биологическое состояние было, но с него сняли копию, оригинал уничтожили, а механический экземпляр сконструировали, что бы он думал, что был биологическим с внедрением воспоминаний.
[Я проистекаю из А (зверски убиенного)]

Я утверждаю, что никто, не объективный наблюдатель, ни сам переселенец в точке времени T не сможет различить этих вариантов. Между получившимися ситуациями нет разницы ни субъективно, ни объективно.

Если мы признаём, что достаточное условие продолжения существования сознания это континуальность восприятия своего существования, нам придётся признать, что принципиальной разницы между вариантами А и В нет. Интуитивно кажется, что это не так, хотя, объективно они идентичны. Чтобы привести правила в соответствие с интуитивными ожиданиями нам придётся наложить условие непрерывности изменений. Недостаточно, чтобы чтобы сознание помнило, что оно непрерывно. Нужно чтобы изменения были постепенными и тогда вроде бы всё в порядке или так по крайней мере кажется.  

Причина опять же в континуальности. Сознание хочет воспринимать (возможно, это специфично не для всех типов сознания) себя континуальным и неприемлет мгновенных скачков.

9. (опционально) Сознание признаёт своими потомками не все последующие состояния, даже если потомок признаёт сознание за предка. Последующее состояние считается приемлимым, если изменения между состояниями достаточно малы или получены методом малых(непрерывных) изменений.

[рис. 8] Что за хмырь впереди меня? Позади меня прошлый я.

Представляется, что сознание не готово воспринимать себя, как набор дискретных состояний. Возможно это свойственно нашей форме сознания, а может быть и сознанию вообще. Поскольку мы решили считать интуитивную оценку сознания мерилом допустимости операции, то в зависимости от этой оценки со стороны конкретного сознания ответ на вопрос о допустимости телепортации и других операций может меняться. 

## Заключение и выводы.

В этой работе я попытался рассмотреть природу сознания как информационного объекта и установить, каким законам он подчиняется. Если принять концепцию зарождения самосознания как результата рекурсивного наблюдения себя, можно, несмотря на субъективность явления, вывести некоторые закономерности поведения этого информационного объекта.

Одна из особенностей сознания относительно прочей информации заключается в свойстве оценивать тождественность себя своим копиям и свойстве запоминать свои предыдущие состояния. Такая ситуация не уникальна. Функция fork ядра linux оперируя над любыми процессами вне зависимости от их сложности также создаёт две нетождественные копии, наследующие одному состоянию, что неудивительно, учитывая что сознание и является вычислительным процессом. Два потока, порождённые вызовом fork различают себя на основе всего двух байт возвращаемого значения и значения pid. Математика таких операций может быть без труда построена, что мы и продемонстрировали в нескольких примерах.

Человеческому сознанию присуща другая особенность. Она заключается в способности к слиянию и разделению, что по-видимому является достаточно уникальным явлением в современной информатике. Философ Дениел Деннет указывает на то, что по своей структуре мозг человека более подобен колонии совместно трудящихся термитов, чем компьютеру, исполняющему программу с централизованным управлением. По-видимому способность человеческого сознания к разделению является особенностью именно этого свойства архитектуры мозга и может не проявляться в других типах вычислительных процессов. 

Изначальная предпосылка вывода строится на постулате "существует, потому что не может не существовать". Возражения к ней могут быть сведены к вопросу "может ли что-то возникнуть из ничего", который не уникален для этой темы и является одним основополагающих филосовских вопросов.

В тексте работы не встречается слово "квалиа". Само по себе "квалиа" - отличный термин обозначающий то, как вещи выглядят для нас, хотя он и чрезмерно затаскан и перенасыщен смысловыми интерпретациями. В работе указано, что сознание должно как-то воспринимать мир, но не указано как именно, и вопрос этот в рамках данной системы построений кажется неразрешимым. Повидимому квалиа должно быть, а вот что оно из себя представляет - загадка за семью печатями.

Автор выражает надежду, что обзор найдёт своего читателя и внесёт некоторую ясность в вопрос взаимозависимости понятий сознания и исскуственного интеллекта, даже если читатель не примет построения полностью. 

Спасибо за внимание.

[1] Стивен Прист: Теории сознания. Глава 1. Дуализм: Платон и Декарт https://gtmarket.ru/laboratory/basis/3283/3284
[2] https://newtonew.com/story/memento
[3] https://www.nkj.ru/news/30619/
[4] http://www.ict.nsc.ru/jspui/bitstream/ICT/885/5/CantheMachinethink.pdf